{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pima = pd.read_csv('diabetes.csv')\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "\n",
    "# X is a matrix, access the features we want in feature_cols\n",
    "X = pima[feature_cols]\n",
    "\n",
    "# y is a vector, hence we use dot to access 'label'\n",
    "y = pima['Outcome']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "576.0\n",
      "192\n",
      "192.0\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(0.75*len(pima))\n",
    "\n",
    "print(len(y_test))\n",
    "print(0.25*len(pima))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y predict:\n",
      " [0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "y test:\n",
      " [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"y predict:\\n\", y_pred)\n",
    "print(\"y test:\\n\", y_test.values.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# create and plot a histogram based on y_test\n",
    "plt.hist(y_test, bins=20)\n",
    "plt.show()\n",
    "\n",
    "# count how many are 0 and 1 (no diabetes, has diabetes)\n",
    "y_test_pd_series = pd.Series(y_test)\n",
    "y_test_pd_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114.  16.]\n",
      " [ 46.  16.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\"Milad\\'s `Code`(not allowed to use)\"\\ndef comp_yt_yp(y_test, y_predict):\\n    # create a blank 2x2 confusion matrix (all 0s)\\n    conf_matrix  = np.zeros((2, 2))\\n    # indices that will create all confusion matrix values\\n    # TP (1,1), TN (0,0), FP (0, 1), FN (1, 0)\\n    for row_index in [0, 1]:\\n        for column_index in [0, 1]:\\n            counter = 0\\n            # iterate through all elements of y_test, y_predict,\\n            # which are all values of either 0 or 1\\n            for (yt_index, yp_index) in zip(y_test, y_predict):\\n                # comparing the elements of y_test and y_predict with each confusion matrix value (TP, TN, FP, FN),\\n                # and if there\\'s a match for the confusion matrix value we\\'re looking at, increment the counter\\n                if (yt_index == row_index) & (yp_index == column_index):\\n                        counter += 1\\n            # Add the total number of elements for the confusion matrix value,\\n            # then look at the next value in the loop\\n            conf_matrix[row_index, column_index] = counter \\n    return conf_matrix\\n\\n# print the result of calculating our confusion matrix\\nprint(comp_yt_yp(y_test, y_pred))\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def pred(y_test, y_predict):\n",
    "    cm  = np.zeros((2, 2))\n",
    "    for ri in [0, 1]: #for each index in each row\n",
    "        for ci in [0, 1]:  #for each index in each col\n",
    "            counter = 0\n",
    "            for (yti, ypi) in zip(y_test, y_predict): #for each index in both Y test and Y predict\n",
    "                if (yti == ri) & (ypi == ci): #if test index == row index + predicted index == col index \n",
    "                        counter += 1 #increment counter by 1 if \n",
    "            cm[ri, ci] = counter \n",
    "    return cm\n",
    "# print the result of calculating our confusion matrix\n",
    "print(pred(y_test, y_pred))\n",
    "\n",
    "\"\"\"\n",
    "\"Milad's `Code`(not allowed to use)\"\n",
    "def comp_yt_yp(y_test, y_predict):\n",
    "    # create a blank 2x2 confusion matrix (all 0s)\n",
    "    conf_matrix  = np.zeros((2, 2))\n",
    "    # indices that will create all confusion matrix values\n",
    "    # TP (1,1), TN (0,0), FP (0, 1), FN (1, 0)\n",
    "    for row_index in [0, 1]:\n",
    "        for column_index in [0, 1]:\n",
    "            counter = 0\n",
    "            # iterate through all elements of y_test, y_predict,\n",
    "            # which are all values of either 0 or 1\n",
    "            for (yt_index, yp_index) in zip(y_test, y_predict):\n",
    "                # comparing the elements of y_test and y_predict with each confusion matrix value (TP, TN, FP, FN),\n",
    "                # and if there's a match for the confusion matrix value we're looking at, increment the counter\n",
    "                if (yt_index == row_index) & (yp_index == column_index):\n",
    "                        counter += 1\n",
    "            # Add the total number of elements for the confusion matrix value,\n",
    "            # then look at the next value in the loop\n",
    "            conf_matrix[row_index, column_index] = counter \n",
    "    return conf_matrix\n",
    "\n",
    "# print the result of calculating our confusion matrix\n",
    "print(comp_yt_yp(y_test, y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  16]\n",
      " [ 46  16]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion)\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61405867, 0.38594133],\n",
       "       [0.7505398 , 0.2494602 ],\n",
       "       [0.74167648, 0.25832352],\n",
       "       [0.60291327, 0.39708673],\n",
       "       [0.88426611, 0.11573389],\n",
       "       [0.87695895, 0.12304105],\n",
       "       [0.50819992, 0.49180008],\n",
       "       [0.44582289, 0.55417711],\n",
       "       [0.77950769, 0.22049231],\n",
       "       [0.25853303, 0.74146697],\n",
       "       [0.67706284, 0.32293716],\n",
       "       [0.17592894, 0.82407106],\n",
       "       [0.65188551, 0.34811449],\n",
       "       [0.81908609, 0.18091391],\n",
       "       [0.57723535, 0.42276465],\n",
       "       [0.84784349, 0.15215651],\n",
       "       [0.55345312, 0.44654688],\n",
       "       [0.92650973, 0.07349027],\n",
       "       [0.53364769, 0.46635231],\n",
       "       [0.64953808, 0.35046192],\n",
       "       [0.52797559, 0.47202441],\n",
       "       [0.60807542, 0.39192458],\n",
       "       [0.84629224, 0.15370776],\n",
       "       [0.55795178, 0.44204822],\n",
       "       [0.89896018, 0.10103982],\n",
       "       [0.77361357, 0.22638643],\n",
       "       [0.94411931, 0.05588069],\n",
       "       [0.25730962, 0.74269038],\n",
       "       [0.89509503, 0.10490497],\n",
       "       [0.83251508, 0.16748492],\n",
       "       [0.58625055, 0.41374945],\n",
       "       [0.65574922, 0.34425078],\n",
       "       [0.81749824, 0.18250176],\n",
       "       [0.62609985, 0.37390015],\n",
       "       [0.9154389 , 0.0845611 ],\n",
       "       [0.61216407, 0.38783593],\n",
       "       [0.55602604, 0.44397396],\n",
       "       [0.8907511 , 0.1092489 ],\n",
       "       [0.72485084, 0.27514916],\n",
       "       [0.71828222, 0.28171778],\n",
       "       [0.75330756, 0.24669244],\n",
       "       [0.59727892, 0.40272108],\n",
       "       [0.77810133, 0.22189867],\n",
       "       [0.73660529, 0.26339471],\n",
       "       [0.33126055, 0.66873945],\n",
       "       [0.99293474, 0.00706526],\n",
       "       [0.89371627, 0.10628373],\n",
       "       [0.82316229, 0.17683771],\n",
       "       [0.67464197, 0.32535803],\n",
       "       [0.75904607, 0.24095393],\n",
       "       [0.717535  , 0.282465  ],\n",
       "       [0.79085101, 0.20914899],\n",
       "       [0.2065381 , 0.7934619 ],\n",
       "       [0.62195525, 0.37804475],\n",
       "       [0.57032158, 0.42967842],\n",
       "       [0.91056727, 0.08943273],\n",
       "       [0.85371019, 0.14628981],\n",
       "       [0.25744554, 0.74255446],\n",
       "       [0.85648956, 0.14351044],\n",
       "       [0.98069321, 0.01930679],\n",
       "       [0.31541112, 0.68458888],\n",
       "       [0.53965397, 0.46034603],\n",
       "       [0.91881687, 0.08118313],\n",
       "       [0.74688679, 0.25311321],\n",
       "       [0.78849857, 0.21150143],\n",
       "       [0.74163683, 0.25836317],\n",
       "       [0.53169448, 0.46830552],\n",
       "       [0.83717831, 0.16282169],\n",
       "       [0.58116011, 0.41883989],\n",
       "       [0.61016075, 0.38983925],\n",
       "       [0.84201271, 0.15798729],\n",
       "       [0.781084  , 0.218916  ],\n",
       "       [0.75640512, 0.24359488],\n",
       "       [0.35984953, 0.64015047],\n",
       "       [0.50882589, 0.49117411],\n",
       "       [0.75744254, 0.24255746],\n",
       "       [0.38253628, 0.61746372],\n",
       "       [0.60871247, 0.39128753],\n",
       "       [0.76336912, 0.23663088],\n",
       "       [0.65281932, 0.34718068],\n",
       "       [0.40808608, 0.59191392],\n",
       "       [0.62838457, 0.37161543],\n",
       "       [0.73326144, 0.26673856],\n",
       "       [0.94558795, 0.05441205],\n",
       "       [0.68804247, 0.31195753],\n",
       "       [0.51428508, 0.48571492],\n",
       "       [0.89069093, 0.10930907],\n",
       "       [0.45252788, 0.54747212],\n",
       "       [0.31466853, 0.68533147],\n",
       "       [0.56772424, 0.43227576],\n",
       "       [0.84315969, 0.15684031],\n",
       "       [0.84773915, 0.15226085],\n",
       "       [0.80287688, 0.19712312],\n",
       "       [0.9365841 , 0.0634159 ],\n",
       "       [0.5567571 , 0.4432429 ],\n",
       "       [0.8333562 , 0.1666438 ],\n",
       "       [0.42195567, 0.57804433],\n",
       "       [0.47798647, 0.52201353],\n",
       "       [0.28156666, 0.71843334],\n",
       "       [0.67443185, 0.32556815],\n",
       "       [0.40366778, 0.59633222],\n",
       "       [0.8920969 , 0.1079031 ],\n",
       "       [0.61916082, 0.38083918],\n",
       "       [0.93349488, 0.06650512],\n",
       "       [0.64886631, 0.35113369],\n",
       "       [0.69576643, 0.30423357],\n",
       "       [0.87037674, 0.12962326],\n",
       "       [0.82041663, 0.17958337],\n",
       "       [0.90773321, 0.09226679],\n",
       "       [0.83227554, 0.16772446],\n",
       "       [0.86352056, 0.13647944],\n",
       "       [0.47592976, 0.52407024],\n",
       "       [0.51399173, 0.48600827],\n",
       "       [0.73368471, 0.26631529],\n",
       "       [0.523284  , 0.476716  ],\n",
       "       [0.58383702, 0.41616298],\n",
       "       [0.83511709, 0.16488291],\n",
       "       [0.79356945, 0.20643055],\n",
       "       [0.84935308, 0.15064692],\n",
       "       [0.18455801, 0.81544199],\n",
       "       [0.49497994, 0.50502006],\n",
       "       [0.23983627, 0.76016373],\n",
       "       [0.57279533, 0.42720467],\n",
       "       [0.45120363, 0.54879637],\n",
       "       [0.88919016, 0.11080984],\n",
       "       [0.90521361, 0.09478639],\n",
       "       [0.6373993 , 0.3626007 ],\n",
       "       [0.68124056, 0.31875944],\n",
       "       [0.62343431, 0.37656569],\n",
       "       [0.91972909, 0.08027091],\n",
       "       [0.77061675, 0.22938325],\n",
       "       [0.98745901, 0.01254099],\n",
       "       [0.86154678, 0.13845322],\n",
       "       [0.28559258, 0.71440742],\n",
       "       [0.53051843, 0.46948157],\n",
       "       [0.49822827, 0.50177173],\n",
       "       [0.84174184, 0.15825816],\n",
       "       [0.52403993, 0.47596007],\n",
       "       [0.80961576, 0.19038424],\n",
       "       [0.86287336, 0.13712664],\n",
       "       [0.77053719, 0.22946281],\n",
       "       [0.6427399 , 0.3572601 ],\n",
       "       [0.91695589, 0.08304411],\n",
       "       [0.58808154, 0.41191846],\n",
       "       [0.57330082, 0.42669918],\n",
       "       [0.90800378, 0.09199622],\n",
       "       [0.84805805, 0.15194195],\n",
       "       [0.74540401, 0.25459599],\n",
       "       [0.88751563, 0.11248437],\n",
       "       [0.65978388, 0.34021612],\n",
       "       [0.81234904, 0.18765096],\n",
       "       [0.53886087, 0.46113913],\n",
       "       [0.84940284, 0.15059716],\n",
       "       [0.80988179, 0.19011821],\n",
       "       [0.33353713, 0.66646287],\n",
       "       [0.85410452, 0.14589548],\n",
       "       [0.13386878, 0.86613122],\n",
       "       [0.87563377, 0.12436623],\n",
       "       [0.66299179, 0.33700821],\n",
       "       [0.13299261, 0.86700739],\n",
       "       [0.59156358, 0.40843642],\n",
       "       [0.65113013, 0.34886987],\n",
       "       [0.93104625, 0.06895375],\n",
       "       [0.82009953, 0.17990047],\n",
       "       [0.51645791, 0.48354209],\n",
       "       [0.82055911, 0.17944089],\n",
       "       [0.48568406, 0.51431594],\n",
       "       [0.88713464, 0.11286536],\n",
       "       [0.8030187 , 0.1969813 ],\n",
       "       [0.71480885, 0.28519115],\n",
       "       [0.88009508, 0.11990492],\n",
       "       [0.49876643, 0.50123357],\n",
       "       [0.74366719, 0.25633281],\n",
       "       [0.50123396, 0.49876604],\n",
       "       [0.43820152, 0.56179848],\n",
       "       [0.74772139, 0.25227861],\n",
       "       [0.31372169, 0.68627831],\n",
       "       [0.57839064, 0.42160936],\n",
       "       [0.79242576, 0.20757424],\n",
       "       [0.87011182, 0.12988818],\n",
       "       [0.69139772, 0.30860228],\n",
       "       [0.24101981, 0.75898019],\n",
       "       [0.69098429, 0.30901571],\n",
       "       [0.62263485, 0.37736515],\n",
       "       [0.81171615, 0.18828385],\n",
       "       [0.8120945 , 0.1879055 ],\n",
       "       [0.58371685, 0.41628315],\n",
       "       [0.80458515, 0.19541485],\n",
       "       [0.76003771, 0.23996229],\n",
       "       [0.87161463, 0.12838537],\n",
       "       [0.77320321, 0.22679679],\n",
       "       [0.76100516, 0.23899484]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
